{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77d5409",
   "metadata": {},
   "source": [
    "# HW9 - Classify Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61adea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Non-allowed imports just to test\n",
    "from json import load\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67eb7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "url = 'https://f000.backblazeb2.com/file/jeldridge-data/012-spanish_french/train.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b50563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = load(open('asdh.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868a86d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f919fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word: str) -> int:\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in vowels and (i == 0 or word[i-1] not in vowels):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def generate_features(word: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates features given a word.\n",
    "    \"\"\"\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    conditions = dict()\n",
    "    \n",
    "    # Letter Counts\n",
    "    conditions['e_count'] = sum(1 for letter in word if letter.lower() in 'e')\n",
    "    conditions['a_count'] = sum(1 for letter in word if letter.lower() in 'a')\n",
    "    conditions['u_count'] = sum(1 for letter in word if letter.lower() in 'u')\n",
    "    conditions['o_count'] = sum(1 for letter in word if letter.lower() in 'o')\n",
    "    \n",
    "    # Presence\n",
    "    conditions['ch_presence'] = 'ch' in word.lower()\n",
    "    conditions['contains_eu'] = 'eu' in word\n",
    "    \n",
    "    # Word Meta\n",
    "    conditions['syllable_count'] = count_syllables(word)\n",
    "    conditions['word_length'] = len(word)\n",
    "    conditions['consonant_vowel_ratio'] = (len(word) - sum(word.lower().count(v) for v in vowels)) /\\\n",
    "                                        max(1, sum(word.lower().count(v) for v in vowels))\n",
    "    \n",
    "    # Prefix/Suffix Analysis\n",
    "    conditions['starts_with_pre'] = word.startswith('pre')\n",
    "    conditions['starts_with_re'] = word.startswith('re') \n",
    "    conditions['ends_with_cion'] = word.endswith('cion') \n",
    "    conditions['ends_in_vowel'] = word[-1] in vowels\n",
    "    conditions['ends_in_two_vowels'] = word[-1] in vowels and word[-2] in vowels\n",
    "    conditions['ends_in_r'] = word[-1] in 'r'\n",
    "    \n",
    "    # Letter Combinations\n",
    "    conditions['ll_presence'] = 'll' in word\n",
    "    conditions['qu_presence'] = 'qu' in word\n",
    "    conditions['ch_presence_fr'] = 'ch' in word\n",
    "    conditions['ou_presence'] = 'ou' in word\n",
    "    \n",
    "    \n",
    "    return pd.Series(conditions)\n",
    "\n",
    "proccess_y = lambda y_set: np.array([word == 'spanish' for word in y_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341ce773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>e_count</th>\n",
       "      <th>a_count</th>\n",
       "      <th>u_count</th>\n",
       "      <th>o_count</th>\n",
       "      <th>ch_presence</th>\n",
       "      <th>contains_eu</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>starts_with_pre</th>\n",
       "      <th>starts_with_re</th>\n",
       "      <th>ends_with_cion</th>\n",
       "      <th>ends_in_vowel</th>\n",
       "      <th>ends_in_two_vowels</th>\n",
       "      <th>ends_in_r</th>\n",
       "      <th>ll_presence</th>\n",
       "      <th>qu_presence</th>\n",
       "      <th>ch_presence_fr</th>\n",
       "      <th>ou_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finalmente</td>\n",
       "      <td>spanish</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>secar</td>\n",
       "      <td>spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word    label  e_count  a_count  u_count  o_count  ch_presence  \\\n",
       "0  finalmente  spanish        2        1        0        0        False   \n",
       "1       secar  spanish        1        1        0        0        False   \n",
       "\n",
       "   contains_eu  syllable_count  word_length  ...  starts_with_pre  \\\n",
       "0        False               4           10  ...            False   \n",
       "1        False               2            5  ...            False   \n",
       "\n",
       "   starts_with_re  ends_with_cion  ends_in_vowel  ends_in_two_vowels  \\\n",
       "0           False           False           True               False   \n",
       "1           False           False          False               False   \n",
       "\n",
       "   ends_in_r  ll_presence  qu_presence  ch_presence_fr  ou_presence  \n",
       "0      False        False        False           False        False  \n",
       "1       True        False        False           False        False  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.assign(**df['word'].transform(generate_features))\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01696b07",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb13456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = features.drop(columns=['label', 'word'])\n",
    "y = features['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e06341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baysian Accuracy: 0.6277777777777778\n"
     ]
    }
   ],
   "source": [
    "# Testing Baysian Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Baysian Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6489bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7055555555555556\n"
     ]
    }
   ],
   "source": [
    "# Testing Random Forrest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4eb56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "# Testing Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "543db26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Accuracy: 0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Testing Ridge Regression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_classifier = RidgeClassifier(random_state=42)\n",
    "ridge_classifier.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_classifier.predict(X_test)\n",
    "accuracy_ridge = accuracy_score(y_test, y_pred_ridge)\n",
    "print(\"Ridge Classifier Accuracy:\", accuracy_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b01731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.6888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Trying SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_classifier = LinearSVC(random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Linear SVM Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "612f6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Trying Decision Tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "y_pred_tree = tree_classifier.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312ad83a",
   "metadata": {},
   "source": [
    "## Implementing Model (Random Forrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb0ee97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:14: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return {'label': mode(y)[0][0]}\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:14: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return {'label': mode(y)[0][0]}\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:33: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return {'label': mode(y)[0][0]}  # If no valid split found, return the majority class\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:33: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return {'label': mode(y)[0][0]}  # If no valid split found, return the majority class\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:92: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  return mode(predictions)[0][0]\n",
      "C:\\Users\\jonat\\AppData\\Local\\Temp\\ipykernel_31996\\3408455585.py:92: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  return mode(predictions)[0][0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6972222222222222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1 or n_samples < 2:\n",
    "            return {'label': mode(y)[0][0]}\n",
    "\n",
    "        # Find best split\n",
    "        best_gini = np.inf\n",
    "        best_feature, best_threshold = None, None\n",
    "        for feature_idx in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_idx] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_idx] > threshold)[0]\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = feature_idx\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        if best_feature is None:\n",
    "            return {'label': mode(y)[0][0]}  # If no valid split found, return the majority class\n",
    "        \n",
    "        left_indices = np.where(X[:, best_feature] <= best_threshold)[0]\n",
    "        right_indices = np.where(X[:, best_feature] > best_threshold)[0]\n",
    "\n",
    "        # Grow left and right subtrees\n",
    "        left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return {'feature_idx': best_feature,\n",
    "                'threshold': best_threshold,\n",
    "                'left': left_subtree,\n",
    "                'right': right_subtree}\n",
    "\n",
    "    def _gini_impurity(self, left_y, right_y):\n",
    "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
    "        p_right = len(right_y) / (len(left_y) + len(right_y))\n",
    "        return p_left * (1 - np.sum(np.square(np.bincount(left_y) / len(left_y)))) + \\\n",
    "               p_right * (1 - np.sum(np.square(np.bincount(right_y) / len(right_y))))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if 'label' in tree:\n",
    "            return tree['label']\n",
    "        else:\n",
    "            if x[tree['feature_idx']] <= tree['threshold']:\n",
    "                return self._predict_tree(x, tree['left'])\n",
    "            else:\n",
    "                return self._predict_tree(x, tree['right'])\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, max_features=None, bootstrap=True):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        if not self.max_features:\n",
    "            self.max_features = int(np.sqrt(n_features))\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            else:\n",
    "                indices = np.arange(n_samples)\n",
    "            X_bootstrap = X[indices]\n",
    "            y_bootstrap = y[indices]\n",
    "\n",
    "            tree = DecisionTree(max_depth=self.max_depth)\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return mode(predictions)[0][0]\n",
    "\n",
    "rf = RandomForest(n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train.to_numpy(), proccess_y(y_train))\n",
    "predictions = rf.predict(X_test.to_numpy())\n",
    "accuracy_score(predictions, proccess_y(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aef6aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
