{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77d5409",
   "metadata": {},
   "source": [
    "# HW9 - Classify Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e61adea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Non-allowed imports just to test\n",
    "import warnings\n",
    "from json import load\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67eb7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Load\n",
    "url = 'https://f000.backblazeb2.com/file/jeldridge-data/012-spanish_french/train.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8536102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = load(open('asdh.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868a86d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f919fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word: str) -> int:\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    word = word.lower()\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in vowels and (i == 0 or word[i-1] not in vowels):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def generate_features(word: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates features given a word.\n",
    "    \"\"\"\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    conditions = dict()\n",
    "    \n",
    "    # Letter Counts\n",
    "    conditions['e_count'] = sum(1 for letter in word if letter.lower() in 'e')\n",
    "    conditions['a_count'] = sum(1 for letter in word if letter.lower() in 'a')\n",
    "    conditions['u_count'] = sum(1 for letter in word if letter.lower() in 'u')\n",
    "    conditions['o_count'] = sum(1 for letter in word if letter.lower() in 'o')\n",
    "    \n",
    "    # Presence\n",
    "    conditions['ch_presence'] = 'ch' in word.lower()\n",
    "    conditions['contains_eu'] = 'eu' in word\n",
    "    \n",
    "    # Word Meta\n",
    "    conditions['syllable_count'] = count_syllables(word)\n",
    "    conditions['word_length'] = len(word)\n",
    "    conditions['consonant_vowel_ratio'] = (len(word) - sum(word.lower().count(v) for v in vowels)) /\\\n",
    "                                        max(1, sum(word.lower().count(v) for v in vowels))\n",
    "    \n",
    "    # Prefix/Suffix Analysis\n",
    "    conditions['starts_with_pre'] = word.startswith('pre')\n",
    "    conditions['starts_with_re'] = word.startswith('re') \n",
    "    conditions['ends_with_cion'] = word.endswith('cion') \n",
    "    conditions['ends_in_vowel'] = word[-1] in vowels\n",
    "    conditions['ends_in_two_vowels'] = word[-1] in vowels and word[-2] in vowels\n",
    "    conditions['ends_in_r'] = word[-1] in 'r'\n",
    "    \n",
    "    # Letter Combinations\n",
    "    conditions['ll_presence'] = 'll' in word\n",
    "    conditions['qu_presence'] = 'qu' in word\n",
    "    conditions['ch_presence_fr'] = 'ch' in word\n",
    "    conditions['ou_presence'] = 'ou' in word\n",
    "    \n",
    "    \n",
    "    return pd.Series(conditions)\n",
    "\n",
    "proccess_y = lambda y_set: np.array([word == 'spanish' for word in y_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71024fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(word: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Generates features given a word.\n",
    "    \"\"\"\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    conditions = dict()\n",
    "    \n",
    "    # Letter Counts\n",
    "    conditions['e_count'] = sum(1 for letter in word if letter.lower() in 'e')\n",
    "    conditions['a_count'] = sum(1 for letter in word if letter.lower() in 'a')\n",
    "    conditions['u_count'] = sum(1 for letter in word if letter.lower() in 'u')\n",
    "    conditions['o_count'] = sum(1 for letter in word if letter.lower() in 'o')\n",
    "    \n",
    "    # Presence\n",
    "    conditions['ch_presence'] = 'ch' in word.lower()\n",
    "    conditions['contains_eu'] = 'eu' in word\n",
    "    \n",
    "    # Word Meta\n",
    "    conditions['syllable_count'] = count_syllables(word)\n",
    "    conditions['word_length'] = len(word)\n",
    "    conditions['consonant_vowel_ratio'] = (len(word) - sum(word.lower().count(v) for v in vowels)) /\\\n",
    "                                        max(1, sum(word.lower().count(v) for v in vowels))\n",
    "    \n",
    "    # Prefix/Suffix Analysis\n",
    "    conditions['starts_with_pre'] = word.startswith('pre')\n",
    "    conditions['ends_in_two_vowels'] = word[-1] in vowels and word[-2] in vowels\n",
    "    conditions['ends_in_r'] = word[-1] in 'r'\n",
    "    \n",
    "    # Letter Combinations\n",
    "    conditions['ll_presence'] = 'll' in word\n",
    "    conditions['qu_presence'] = 'qu' in word\n",
    "    conditions['ch_presence_fr'] = 'ch' in word\n",
    "    conditions['ou_presence'] = 'ou' in word\n",
    "    \n",
    "    \n",
    "    return pd.Series(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341ce773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>e_count</th>\n",
       "      <th>a_count</th>\n",
       "      <th>u_count</th>\n",
       "      <th>o_count</th>\n",
       "      <th>ch_presence</th>\n",
       "      <th>contains_eu</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>word_length</th>\n",
       "      <th>consonant_vowel_ratio</th>\n",
       "      <th>starts_with_pre</th>\n",
       "      <th>ends_in_two_vowels</th>\n",
       "      <th>ends_in_r</th>\n",
       "      <th>ll_presence</th>\n",
       "      <th>qu_presence</th>\n",
       "      <th>ch_presence_fr</th>\n",
       "      <th>ou_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finalmente</td>\n",
       "      <td>spanish</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>secar</td>\n",
       "      <td>spanish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word    label  e_count  a_count  u_count  o_count  ch_presence  \\\n",
       "0  finalmente  spanish        2        1        0        0        False   \n",
       "1       secar  spanish        1        1        0        0        False   \n",
       "\n",
       "   contains_eu  syllable_count  word_length  consonant_vowel_ratio  \\\n",
       "0        False               4           10                    1.5   \n",
       "1        False               2            5                    1.5   \n",
       "\n",
       "   starts_with_pre  ends_in_two_vowels  ends_in_r  ll_presence  qu_presence  \\\n",
       "0            False               False      False        False        False   \n",
       "1            False               False       True        False        False   \n",
       "\n",
       "   ch_presence_fr  ou_presence  \n",
       "0           False        False  \n",
       "1           False        False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.assign(**df['word'].transform(generate_features))\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01696b07",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb13456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "X = features.drop(columns=['label', 'word'])\n",
    "y = features['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6abf014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true, y_true = zip(*true.items())\n",
    "true_df = pd.DataFrame({'word': X_true, 'label': y_true})\n",
    "true_features = true_df.assign(**true_df['word'].transform(generate_features))\n",
    "true_X = true_features.drop(columns=['label', 'word'])\n",
    "true_y = true_features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e06341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baysian Accuracy: 0.6361111111111111\n"
     ]
    }
   ],
   "source": [
    "# Testing Baysian Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Baysian Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6489bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Testing Random Forrest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d4eb56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Testing Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "y_pred_gb = gb_classifier.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543db26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Accuracy: 0.6861111111111111\n"
     ]
    }
   ],
   "source": [
    "# Testing Ridge Regression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_classifier = RidgeClassifier(random_state=42)\n",
    "ridge_classifier.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_classifier.predict(X_test)\n",
    "accuracy_ridge = accuracy_score(y_test, y_pred_ridge)\n",
    "print(\"Ridge Classifier Accuracy:\", accuracy_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b01731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Accuracy: 0.6861111111111111\n"
     ]
    }
   ],
   "source": [
    "# Trying SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "svm_classifier = LinearSVC(random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Linear SVM Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "612f6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6805555555555556\n"
     ]
    }
   ],
   "source": [
    "# Trying Decision Tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "y_pred_tree = tree_classifier.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d25b9",
   "metadata": {},
   "source": [
    "## Implementing Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e31ff266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features=None, impurity_measure='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.impurity_measure = impurity_measure\n",
    "        self.root = None\n",
    "\n",
    "    def gini_impurity(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        gini = 1 - np.sum(probabilities ** 2)\n",
    "        return gini\n",
    "\n",
    "    def entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    def impurity(self, y):\n",
    "        if self.impurity_measure == 'gini':\n",
    "            return self.gini_impurity(y)\n",
    "        elif self.impurity_measure == 'entropy':\n",
    "            return self.entropy(y)\n",
    "\n",
    "    def information_gain(self, X, y, feature_index):\n",
    "        left_indices = X.iloc[:, feature_index] <= X.iloc[:, feature_index].median()\n",
    "        right_indices = ~left_indices\n",
    "        left_y = y[left_indices]\n",
    "        right_y = y[right_indices]\n",
    "        parent_impurity = self.impurity(y)\n",
    "        left_impurity = self.impurity(left_y)\n",
    "        right_impurity = self.impurity(right_y)\n",
    "        left_weight = len(left_y) / len(y)\n",
    "        right_weight = len(right_y) / len(y)\n",
    "        info_gain = parent_impurity - (left_weight * left_impurity + right_weight * right_impurity)\n",
    "        return info_gain\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        if self.max_features is not None:\n",
    "            feature_indices = np.random.choice(num_features, self.max_features, replace=False)\n",
    "        else:\n",
    "            feature_indices = range(num_features)\n",
    "\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "\n",
    "        if (np.all(y == y[0]) or\n",
    "            depth == self.max_depth or\n",
    "            len(y) < self.min_samples_split or\n",
    "            len(np.unique(y)) == 1):\n",
    "            return Node(value=np.bincount(y).argmax())\n",
    "\n",
    "        for feature_index in feature_indices:\n",
    "            gain = self.information_gain(X, y, feature_index)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_index\n",
    "\n",
    "        if best_feature is None:\n",
    "            return Node(value=np.bincount(y).argmax())\n",
    "\n",
    "        threshold = X.iloc[:, best_feature].median()\n",
    "        left_indices = np.where(X.iloc[:, best_feature] <= threshold)[0]\n",
    "        right_indices = np.where(X.iloc[:, best_feature] > threshold)[0]\n",
    "\n",
    "        if len(left_indices) < self.min_samples_leaf or len(right_indices) < self.min_samples_leaf:\n",
    "            return Node(value=np.bincount(y).argmax())\n",
    "\n",
    "        left_X = X.iloc[left_indices, :]\n",
    "        right_X = X.iloc[right_indices, :]\n",
    "        left_y = y[left_indices]\n",
    "        right_y = y[right_indices]\n",
    "        left_node = self.build_tree(left_X, left_y, depth + 1)\n",
    "        right_node = self.build_tree(right_X, right_y, depth + 1)\n",
    "        return Node(best_feature, threshold, left_node, right_node)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for i, row in X.iterrows():\n",
    "            node = self.root\n",
    "            while node.left and node.right:\n",
    "                if row[node.feature_index] <= node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            predictions[i] = node.value\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae62066",
   "metadata": {},
   "source": [
    "## True Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "248da2a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d233866e6253453ebe46bbb69413ce6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Decision Tree:   0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Depth=7, Min Samples Split=2, Max Features=8, Impurity=entropy, Average Score=0.7329\n",
      "Rank 2: Depth=5, Min Samples Split=3, Max Features=11, Impurity=entropy, Average Score=0.7295\n",
      "Rank 3: Depth=9, Min Samples Split=0, Max Features=11, Impurity=gini, Average Score=0.7295\n",
      "Rank 4: Depth=7, Min Samples Split=5, Max Features=7, Impurity=entropy, Average Score=0.7260\n",
      "Rank 5: Depth=9, Min Samples Split=1, Max Features=6, Impurity=entropy, Average Score=0.7260\n",
      "Rank 6: Depth=13, Min Samples Split=4, Max Features=10, Impurity=entropy, Average Score=0.7260\n",
      "Rank 7: Depth=23, Min Samples Split=9, Max Features=9, Impurity=gini, Average Score=0.7260\n",
      "Rank 8: Depth=9, Min Samples Split=8, Max Features=3, Impurity=gini, Average Score=0.7226\n",
      "Rank 9: Depth=10, Min Samples Split=1, Max Features=15, Impurity=entropy, Average Score=0.7226\n",
      "Rank 10: Depth=15, Min Samples Split=7, Max Features=7, Impurity=gini, Average Score=0.7226\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": range(25),\n",
    "    \"min_samples_split\": range(10),\n",
    "    \"max_features\": [None] + list(range(17)),\n",
    "    \"impurity_measure\": ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "total_combinations = len(params['max_depth']) * len(params['min_samples_split']) * len(params['max_features']) * len(params['impurity_measure'])\n",
    "pbar = tqdm(total=total_combinations, desc=\"Training Decision Tree\")\n",
    "\n",
    "for depth in params['max_depth']:\n",
    "    for min_samples in params['min_samples_split']:\n",
    "        for features in params['max_features']:\n",
    "            for impurity in params['impurity_measure']:\n",
    "                clf = DecisionTreeClassifier(\n",
    "                    max_depth=depth,\n",
    "                    min_samples_split=min_samples,\n",
    "                    max_features=features,\n",
    "                    impurity_measure=impurity\n",
    "                )\n",
    "                clf.fit(X, proccess_y(y))\n",
    "                preds = clf.predict(true_X)\n",
    "                score = accuracy_score(preds, proccess_y(y_true))\n",
    "                scores[(depth, min_samples, features, impurity)].append(score)\n",
    "                pbar.update(1)\n",
    "\n",
    "sorted_scores = sorted(scores.items(), key=lambda x: sum(x[1]) / len(x[1]), reverse=True)\n",
    "\n",
    "for i, (params, scores) in enumerate(sorted_scores[:10]):\n",
    "    depth, min_samples, features, impurity = params\n",
    "    avg_score = sum(scores) / len(scores)\n",
    "    print(f\"Rank {i+1}: Depth={depth}, Min Samples Split={min_samples}, Max Features={features}, Impurity={impurity}, Average Score={avg_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
